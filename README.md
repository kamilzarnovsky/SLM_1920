# SLM_1920
Repository for Statistical Learning Methods [223490-0286] - Summer semester 2019/20


---
**Modeling problem report**

Every student will be assigned to one dataset from [UCI Repository](https://archive.ics.uci.edu/ml/datasets.php).
The task is to analyze the data and produce a report with following structure:

`5pts` 1) Introduction, problem description (regression/classification/clustering/etc.), target variable and features explanation

`10pts` 2) Cleaning and preprocessing data - removing or imputing missing data, standarization, one-hot encoding, handling outliers, etc.

`10pts` 3) EDA with focus on exploring relations between features nad target variable

`5pts` 4) Creating models, hyperparameter tuning

`10pts` 5) Graphical and descriptive model assessment

`10pts` 6) Summary, discussion on encountered problems and their solution e.g. how overfitting was avoided or imbalanced data mitigated

Code and descriptions/comments should be in Jupyter or R Markdown notebook. If you wish, you are allowed to choose either R or Python (also remember there is Jupyter kernel for R). Please send reports to _kinga.siuta@gmail.com_ with following naming convention <index_number>_SLM_S1920_Report.< extension > before **10.06.2020r. EOD**. 
  
Each email should have 2 attachments: 
- for Jupyter: `.ipynb` file and `.html/.pdf` file generated from notebook, 
- for R Markdown:  `.Rmd` file and `.html/.pdf` file generated from notebook.


---
**Contact**

Name: Kinga Siuta

Email: kinga.siuta@gmail.com

---
**Lecturers**

• lecturer: Bogumił Kamiński

• laboratories: 

Groups 100 and 101 – Michał Kot, 

Group 102 – Kinga Siuta, 

Group 103 - Agata Skorupka, 

Groups 104 and 105 – Łukasz Kraiński

---
**Schedule**

• lectures: Tuesdays, 8:00-10:35, Aula IV

• laboratories: room A-113;

---
**Lectures**

|Date |Subject|
|-----|-------|
|25-02-20 | Introduction to data science; McKinsey case study|
|03-03-20 | Working with Git and Github|
|10-03-20 | Introduction to Julia programming for data science|
|17-03-20 | Introduction to predictive modeling|
|24-03-20 | Introduction to threading and distributed computing K-nearest neighbors algorithm|
|31-03-20 | Methods of evaluation of predictive model quality|
|07-04-20 | Working with data frames in Julia|
|21-04-20 | Methods of predictive model selection|
|28-04-20 | Regularization for predictive modeling|
|05-05-20 | Introduction to approximation and local predictive models|
|12-05-20 | Introduction to deep learning|
|19-05-20 | Causality modeling: introduction|
|26-05-20 | Causality modeling: algorithms|
|02-06-20 | Storytelling with data|
|09-06-20 | Data science in production environments + written examination|

---
**Laboratories**
|# |Subject|
|--|-------|
|1 |Refresher on R and Python programming|
|2 |Methods of evaluation of classifiers|
|3 |Nonparametric regression models: smoothing spline, LOESS, GAM|
|4 |Classical machine learning models: CART, random forest|
|5 |Deep learning|
|6 |Modeling competition|
|7 |Computer exam|

---
**Literature**

Stephen Boyd and Lieven Vandenberghe, Introduction to Applied Linear Algebra
(http://vmls-book.stanford.edu/)

Gareth J., Witten D., Hastie T., Tibshirani R. (2013), An Introduction to Statistical Learning
with Applications in R (http://www-bcf.usc.edu/~gareth/ISL/)

Hastie T., Tibshirani R., Friedman J. (2013), The Elements of Statistical Learning
(http://www-stat.stanford.edu/~tibs/ElemStatLearn/)

Optional: Kamiński B., Zawisza M. (2012), Receptury w R. Podręcznik dla ekonomisty, Oficyna
Wydawnicza SGH (http://bogumilkaminski.pl/projekty/)

Optional: B. Kamiński, P. Szufel: Julia 1.0 Programming Cookbook, Packt Publishing, 2018
(https://www.packtpub.com/application-development/julia-10-programming-cookbook)

---
**Course evaluation criteria**

<s>• Written examination (50 points); during last lecture; no supporting materials are allowed</s>

• Modeling problem report (50 points); sent to your teaching assistant before last laboratory, subject of modelling should be agreed with teaching assistant

• Laboratory examination (50 points); during last examination; you can bring your own printed
materials

• Possible extra points: homeworks, competition

---
**Grading rules**
|From |To|Final grade|
|-----|--|--------|
|0 |49| 2.0|
|50 |59 |3.0|
|60 |69 |3.5|
|70 |79 |4.0|
|80 |89 |4.5|
|90 |100 |5.0|
